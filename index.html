<!doctype html>
<html lang="en">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css"
        integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans+Condensed&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono&display=swap" rel="stylesheet">

    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.1/css/all.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.9.3/Chart.min.js"></script>

    <style>
        .main {
            font-family: 'IBM Plex Sans Condensed', sans-serif;
        }

        .code {
            font-family: 'IBM Plex Mono', monospace;
        }

        .a {
            color: gainsboro;
            font-family: 'IBM Plex Sans Condensed', sans-serif;
        }
    </style>

    <title>Adaptive BatchNorm</title>
</head>

<body>
    <div class="container main">
        <div class="row">
            <div class="col-sm-2">
            </div>
            <div class="col-sm-8" id="main-content">
                <div class="row text-center my-5" id="#">
                    <h1>Improving robustness against common corruptions by covariate shift adaptation</h1>
                </div>

                <!-- Begin author list-->
                <div class="row text-center mb-4">
                    <div class="col-sm-4 mb-4">
                        Steffen Schneider*
                        <a href="mailto:steffen@bethgelab.org"><i class="far fa-envelope"></i></a>
                        <a href="https://stes.io" target="_blank"><i class="fas fa-link"></i></a></br>
                        University of Tübingen & <nobr>IMPRS-IS</nobr>
                    </div>
                    <div class="col-sm-4 mb-4">
                        Evgenia Rusak*
                        <a href="mailto:evgenia.rusak@bethgelab.org"><i class="far fa-envelope"></i></a></br>
                        University of Tübingen & <nobr>IMPRS-IS</nobr>
                    </div>
                    <div class="col-sm-4  mb-4">
                        Luisa Eck<br>
                        LMU Munich
                    </div>
                    <div class="col-sm-4  mb-4">
                        Oliver Bringmann
                        <a href="https://embedded.uni-tuebingen.de/en/team/oliver-bringmann" target="_blank"><i
                                class="fas fa-link"></i></a><br>
                        University of Tübingen
                    </div>
                    <div class="col-sm-4  mb-4">
                        Wieland Brendel<br>
                        University of Tübingen
                    </div>
                    <div class="col-sm-4  mb-4">
                        Matthias Bethge
                        <a href="http://bethgelab.org/people" target="_blank"><i class="fas fa-link"></i></a><br>
                        University of Tübingen & <nobr>Amazon Tübingen</nobr>
                    </div>
                </div>
                <!-- End author list-->

                <div class="row text-center">
                    <div class="col-sm-3 mb-3">
                        <h4>
                            <a href="https://arxiv.org/pdf/2006.16971.pdf">
                            <i class="fas fa-file-alt"></i>
                            Paper
                        </a>
                        </h4>
                    </div>
                    <div class="col-sm-3 mb-3">
                        <h4>
                            <a href="http://www.gatsby.ucl.ac.uk/~balaji/udl2020/accepted-papers/UDL2020-paper-002.pdf">
                            <i class="far fa-file-alt"></i>
                            Workshop 
                        </a>
                        </h4>
                    </div>
                    <div class="col-sm-3 mb-3">
                        <h4>
                            <a href="200709_BatchNormAdapt.pdf"> <i class="far fa-chart-bar"></i>
                                Slides
                            </a>
                        </h4>
                    </div>
                    <div class="col-sm-3 mb-3">
                        <h4>
                            <a href="https://github.com/bethgelab/robustness"> <i class="fab fa-github"></i>
                                Code
                            </a>
                        </h4>
                    </div>
                </div>

                <div class="row text-center">
                    <p>
                        <b>tl;dr:</b>
                        <span class="text-muted">We propose to go beyond the assumption of a single sample
                            from the target domain when evaluating robustness.
                            Re-computing BatchNorm statistics is a simple baseline algorithm for improving the
                            corruption error up to 14% points over a wide range of models, when access to more than a
                            single sample is possible.
                        </span>
                    </p>
                </div>

                <div class="row mt-2">
                    <h3>News</h3>
                </div>

                <div class="row">
                    <ul>
                    <li> September '20: Our paper was accepted for poster presentation at <a href="https://neurips.cc/Conferences/2020">NeurIPS 2020</a>.
                        We will update the arXiv version accordingly. Stay tuned for the code release.
                    </li>
                    <li> July '20: A shorter <a href="http://www.gatsby.ucl.ac.uk/~balaji/udl2020/accepted-papers/UDL2020-paper-002.pdf">
                        <i class="far fa-sticky-note"></i> workshop version
                    </a>
                    of the paper was accepted for oral presentation at the <a href="https://sites.google.com/view/udlworkshop2020" target="_blank">Uncertainty & Robustness in Deep Learning</a> Workshop at ICML 2020.
                    </li>
                    <li> June '20: The pre-print is available on arXiv: <a href="https://arxiv.org/abs/2006.16971.pdf">arxiv.org/abs/2006.16971.pdf</a>
                    </li>
                    </ul>
                </div>

                <div class="row mt-2">
                    <h3>Abstract</h3>
                </div>
                <div class="row">
                    <p>
                        Today's state-of-the-art machine vision models are vulnerable to image corruptions like blurring
                        or compression artefacts, limiting their performance in many real-world applications.
                        We here argue that popular benchmarks to measure model robustness against common corruptions
                        (like ImageNet-C) underestimate model robustness in many (but not all) application scenarios.
                        The key insight is that in many scenarios, multiple unlabeled examples of the corruptions are
                        available and can be used for unsupervised online adaptation.
                        Replacing the activation statistics estimated by batch normalization on the training set with
                        the statistics of the corrupted images consistently improves the robustness across 25 different
                        popular computer vision models.
                        Using the corrected statistics, ResNet-50 reaches 62.2% mCE on ImageNet-C compared to 76.7%
                        without adaptation.
                        With the more robust AugMix model, we improve the state of the art from 56.5% mCE to 51.0% mCE.
                        Even adapting to a single sample improves robustness for the ResNet-50 and AugMix models, and 32
                        samples are sufficient to improve the current state of the art for a ResNet-50 architecture.
                        We argue that results with adapted statistics should be included whenever reporting scores in
                        corruption benchmarks and other out-of-distribution generalization settings.
                    </p>
                </div>

                <div class="row mt-2">
                    <h3>Method</h3>
                </div>

                <div class="row">
                    <p>
                        Batch Normalization statistics are typically estimated on the training dataset.
                        Under covariate shift in the inputs (e.g., by adding image corruptions), these statistics are no longer valid.
                        We investigate improvements of various computer vision models when estimating statistics on the test dataset.
                        To cover settings with small sample sizes \(n\) on the target domain, we optionally combine source and target statistics using \(N\) pseudo-samples from the source domain.
                        This yields the following corrected normalization statistics:
                    </p>
                    <p class="text-center">
                        $$
                        \bar{\mu} = \frac{N \mu_s}{N + n} + \frac{n \mu_t}{N + n} , \quad
                        \bar{\sigma}^2 = \frac{N \sigma_s^2}{N + n} + \frac{n \sigma_t^2}{N + n} .
                        $$
                    </p>
                </div>


                <div class="row mt-2">
                    <h3>Dataset</h3>
                </div>

                <div class="row">
                    <p>We consider ImageNet-C comprised of 15 test and 4 holdout corruptions as the main dataset in our study. We run ablations on IN-V2, IN-A and ObjectNet and will consider recently released datasets in updates of our pre-print. Gains are only to be expected on dataset with a clearly defined and systematic domain shifts, such as in ImageNet-C.
                    On other datasets, more powerful <a href="https://domainadaptation.org/" target="_blank">domain adaptation</a> methods are likely needed to correct the shift.
                    </p>
                </div>

                <div class="row">
                    <div class="rounded col-lg-1"></div>
                    <div class="rounded col-lg-10">
                        <div class="w-100 pt-10"
                            style="background-image: url(inc.png); background-repeat: no-repeat; background-size: contain, cover; min-height: 300px;">
                        </div>
                        <small class="text-muted">Overview of corruptions in the ImageNet-C dataset. Each corruption is applied in five different severities.
                            In total, this yields 15x5 test corruptions and 4x5 holdout corruptions.
                            While our method is generally hyperparameter free, the pseudo-batchsize \(N\) is selected on the holdout set for the small sample results.
                        </small>
                    </div>
                    <div class="rounded col-lg-2"></div>
                </div>

                <div class="row mt-2">
                    <h3>Key Results</h3>
                </div>

                <div class="row">
                    <h4>Adaptation boosts robustness of a vanilla trained ResNet-50 model</h4>
                    <p>
                        We found that the robustness of computer vision models based on the ResNet-50 architecture is
                        currently underestimated and can be substantially improved if access to more than one target sample is allowed.
                        When employing the corrected statistics to normalize the network, we see performance
                        improvements of as much as 14% points mCE.
                    </p>
                    <p>
                        The exact value depends on the target domain batchsize and the source domain pseudo-batchsize.
                        The following plot shows the dependency of performance on IN-C and number of unlabeled target
                        domain samples we can access, for the best pseudo-batchsize \(N\) selected on the holdout set existing for this purpose (solid lines), or the default \(N = 0\) (dashed line).
                    </p>
                </div>
                <div class="row text-center align-center">
                    <div class="col-lg-10">
                        <canvas id="canvas-batchsize"></canvas>
                    </div>
                </div>


                <div class="row mt-2">
                    <h4>Adaptation consistently improves corruption robustness across IN trained models</h4>
                    <p>
                        We benchmarked the improvement of model robustness for all computer vision architectures
                        implemented in
                        the torchvision library.
                        We find consistent improvements, typically on the order of 10% points, when using the proposed
                        adaptation scheme.
                    </p>
                </div>
                <div class="row text-center align-center">
                    <canvas id="canvas-torchvision"></canvas>
                </div>

                <div class="row mt-2">
                    <h4>Adaptation yields new state of the art on IN-C for robust models.</h4>
                    <p>
                        Besides vanilla trained ResNets, we also explore a variety of robust models part of the <a
                        href="https://github.com/hendrycks/robustness#imagenet-c-leaderboard" target="_blank">IN-C
                        Leaderboard</a>.
                        We see considerable improvement across all of these models for a sufficient number of samples
                        from the target domain.
                    </p>
                    <div class="mx-auto align-center text-center my-4">
                        <img class="w-75" src="table.png">
                    </div>
                    <p>
                        In the following, we investigate the result in more detail and show results for different pseudo batchsizes (color) and target dataset sizes (x axis).
                        We provide a theoretical model qualitatively explaining the observed behavior in the paper.
                    </p>
                    <div class="row text-center align-center">
                        <div class="col-lg-12">
                            <canvas id="canvas-priors" class="mx-auto"></canvas>
                        </div>
                        <div class="btn-group align-center text-center mx-auto" role="group" aria-label="Basic example">
                            <button type="button" class="btn btn-secondary" id="select_sin">SIN</button>
                            <button type="button" class="btn btn-secondary" id="select_ant">ANT</button>
                            <button type="button" class="btn btn-secondary" id="select_antsin">ANT+SIN</button>
                            <button type="button" class="btn btn-secondary" id="select_augmix">AugMix</button>
                            <button type="button" class="btn btn-secondary" id="select_resnet">ResNet-50</button>
                        </div>
                    </div>
                </div>
                
                <div class="row mt-2">
                    <h3>Additional Results</h3>
                </div>
                <div class="row">
                    <p>
                    Please have a look at our
                    <a href="https://arxiv.org/pdf/2006.16971.pdf">
                    <i class="far fa-sticky-note"></i>
                    pre-print</a> for further results.
                    We will also soon release 
                    <a href="https://github.com/bethgelab/robustness"> <i class="fab fa-github"></i>
                        code
                    </a>
                    for reproducing our experiments.
                    Please <a href="mailto:steffen@bethgelab.org">reach out</a> if you have any additional questions.
                    </p>
                </div>

                <div class="row">
                    <h3>BibTeX</h3>
                </div>
                <div class="row">
                    <p>If you find our analysis helpful, please cite our pre-print:</p>
                </div>
                <div class="row justify-content-md-center">
                    <div class="col-sm-10 rounded p-3 m-2" style="background-color:lightgray;">
                        <small class="code">
                            @article{schneider2020betterinc,<br>
                            &nbsp;&nbsp;author = { Schneider, Steffen and Rusak, Evgenia<br>
                            &nbsp;&nbsp;&nbsp;&nbsp;and Eck, Luisa and Bringmann, Oliver<br>
                            &nbsp;&nbsp;&nbsp;&nbsp;and Brendel, Wieland and Bethge, Matthias<br>
                            &nbsp;&nbsp;},<br>
                            &nbsp;&nbsp;title = {Removing covariate shift improves<br>
                            &nbsp;&nbsp;&nbsp;&nbsp;robustness against common corruptions<br>
                            &nbsp;&nbsp;},<br>
                            &nbsp;&nbsp;journal = {CoRR},<br>
                            &nbsp;&nbsp;volume = {abs/2006.16971},<br>
                            &nbsp;&nbsp;year = {2020},<br>
                            }
                        </small>
                    </div>
                </div>

                <div class="row">
                    <small class="text-muted">Webpage designed using Bootstrap 4.5 and Chart.js.</small>
                    <a href="#" class="ml-auto"><i class="fas fa-sort-up"></i></a>
                </div>

            </div>
        </div>

    </div>




    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

    <script src="data.js"></script>

    <script src="plot-bsz.js"></script>
    <script src="plot-torchvision.js"></script>
    <script src="plot-all-models.js"></script>

    <script>

        window.onload = function () {
            window.plotBatchsize = new Chart(
                document.getElementById('canvas-batchsize').getContext('2d'),
                config_batchsize);
            window.plotTorchvision = new Chart(
                document.getElementById('canvas-torchvision').getContext('2d'),
                config_torchvision);
            window.plotPriors = new Chart(
                document.getElementById('canvas-priors').getContext('2d'),
                config_priors);

            [sin, ant, antsin, augmix, resnet].forEach(func => {
                $(`#select_${func.name}`).click(function () {
                    new_dataset = get_datasets_priors(func);
                    window.plotPriors.config.data.datasets.forEach((ds, idx) => {
                        //ds.data.length = 0;
                        //new_dataset[idx].data.forEach(sample => ds.data.push(sample));
                        ds.data = new_dataset[idx].data;
                    });
                    window.plotPriors.update({ duration: 800, easing: 'easeInOutCubic' });
                });
            });
        };
    </script>

</body>

</html>
